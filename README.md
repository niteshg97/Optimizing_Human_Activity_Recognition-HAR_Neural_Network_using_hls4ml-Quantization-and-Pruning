# ğŸ§  Human Activity Recognition (HAR) â€” Model Compression & FPGA Deployment using hls4ml ğŸš€  

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![hls4ml](https://img.shields.io/badge/hls4ml-FPGA--Optimized-green.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## ğŸ—ï¸ Project Overview  

This project presents a **novel approach to model compression and FPGA deployment** for a **Human Activity Recognition (HAR)** model using **quantization**, **pruning**, and **decomposition techniques**. This project optimizes a Keras HAR neural
network using 16-bit quantization and 80% pruning. The result is a low-latency, low-power design ideal
for real-time edge AI, with applications in wearable fitness trackers, real-time fall detection, and
industrial IoT monitoring.

The workflow combines **TensorFlow**, **TensorFlow Model Optimization Toolkit (TF-MOT)**, and **hls4ml** to generate FPGA-ready hardware implementations while achieving an optimal **performance-efficiency trade-off**.  

---

## ğŸ¯ Objectives  

âœ… Develop a lightweight, high-accuracy ML model for HAR  
âœ… Integrate **quantization**, **pruning**, and **model decomposition** techniques  
âœ… Achieve **FPGA synthesis** using `hls4ml` for hardware efficiency  
âœ… Analyze **accuracy vs. latency vs. resource utilization** trade-offs  

---

## âš™ï¸ Tools & Frameworks Used  

| Tool / Framework | Purpose |
|------------------|----------|
| ğŸ§© **TensorFlow / Keras** | Model training and evaluation |
| âœ‚ï¸ **TensorFlow Model Optimization Toolkit** | Model pruning & quantization |
| âš¡ **hls4ml** | High-Level Synthesis for FPGA deployment |
| ğŸ“Š **scikit-learn & NumPy** | Data preprocessing and evaluation |
| ğŸ’¾ **Vivado HLS / Vitis HLS (optional)** | FPGA synthesis and simulation |
| â˜ï¸ **Google Colab** | Training and HLS conversion environment |

---

## ğŸ§  Model Architecture  

| Layer | Type | Output Shape | Activation |
|--------|------|---------------|-------------|
| Input | Dense | (561,) | â€” |
| Dense-1 | Fully Connected | 64 | ReLU |
| Dense-2 | Fully Connected | 32 | ReLU |
| Output | Fully Connected | 6 | Softmax |

**Dataset:** UCI Human Activity Recognition (HAR)  
**Classes:** WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING  

---

## ğŸ§® Methodology  

### ğŸ”¹ Phase 1 â€” Baseline Training  
- Trained the model using Keras on the UCI HAR dataset  
- Achieved **95.18% accuracy** on test data  

### ğŸ”¹ Phase 2 â€” Quantization  
- Converted model to **fixed-point precision (`ap_fixed<16,6>`)**  
- Verified minimal loss in accuracy  

### ğŸ”¹ Phase 3 â€” Pruning & Fine-Tuning  
- Applied **80% pruning** using TensorFlow MOT  
- Fine-tuned model to recover accuracy  

### ğŸ”¹ Phase 4 â€” hls4ml Conversion  
- Converted the optimized model into an FPGA-compatible HLS project  
- Compiled and tested **C-simulation** successfully  

---

## ğŸ“Š Performance Summary  

| Configuration | Reuse Factor | Accuracy | Latency | Resource Usage |
|----------------|--------------|-----------|----------|----------------|
| Baseline Keras | â€” | **95.18%** | â€” | â€” |
| Quantized Model | 1 | **93.9%** | Low | High |
| Pruned (80%) | 1 | **93.5%** | Low | Very Low |
| Serialized (RF=51) | 51 | **93.9%** | High | Lowest |

---

## âš¡ FPGA Configuration  

| Parameter | Value |
|------------|--------|
| Target FPGA | `xc7k160t-fbg484-1` |
| Clock Period | `5 ns` |
| IO Type | `io_parallel` |
| Precision | `ap_fixed<16,6>` |
| Reuse Factor | `1` and `51` (tested) |

---

## ğŸ“ Repository Structure  

```bash
.
â”œâ”€â”€ Optimizing_a_HAR_Neural_Network.ipynb     # Google Colab notebook (main project)
â”œâ”€â”€ har_model.h5                              # Baseline trained model
â”œâ”€â”€ har_model_pruned.h5                       # 80% pruned fine-tuned model
â”œâ”€â”€ HAR_HLS4ML_Project.zip                    # hls4ml-generated FPGA project files
â””â”€â”€ README.md                                 # This file




---
```
## ğŸš€ Quick Start (Google Colab)

```bash

# Install dependencies
!pip install tensorflow tensorflow-model-optimization hls4ml scikit-learn numpy

# Run the notebook
execute Optimizing_a_HAR_Neural_Network.ipynb


```

## ğŸ§© Key Learnings  

- âš™ï¸ **Fixed-point quantization** can significantly reduce FPGA latency and area with minimal accuracy drop.  
- âœ‚ï¸ **Structured pruning (up to 80%)** improves synthesis efficiency without heavy accuracy degradation.  
- ğŸ§® **Removing or linearizing Softmax** before `hls4ml` conversion prevents C++ compile issues (`implementation` field mismatch).  
- ğŸ¤ **Combining compression and hardware co-design** yields real-time performance on embedded devices.  



## ğŸ™Œ Acknowledgements  

- [UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)  
- [hls4ml â€” FastMachineLearning Project](https://github.com/fastmachinelearning/hls4ml)  
- [TensorFlow Model Optimization Toolkit](https://www.tensorflow.org/model_optimization)  
- [Google Colab](https://colab.research.google.com)  

## ğŸ‘¨â€ğŸ’» Author  

**Nitesh Kumar**  
ğŸ“§ niteshk.ug23.ee@nitp.ac.in  
ğŸŒ [LinkedIn Profile](https://www.linkedin.com/in/nitesh-kumar-68a698275)  




## ğŸ›¡ï¸ License  

**MIT License**  
Copyright (c) 2025 Nitesh Kumar







...

